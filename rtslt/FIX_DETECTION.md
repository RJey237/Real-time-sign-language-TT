# Sign Detection Not Working - ROOT CAUSE & FIXES

## ðŸ”´ ROOT CAUSES IDENTIFIED

### 1. **CRITICAL BUG: Wrong Landmark Normalization**
**Location**: `ml_models/inference.py` â†’ `_normalize_landmarks()` method

**The Problem:**
```python
# WRONG âŒ (Old code)
landmarks = landmarks * 2.0 - 1.0  # Converts [0,1] â†’ [-1,1]
```

**Why It's Wrong:**
- Model was trained on landmarks in **[0, 1] range** (from MediaPipe)
- Your code converts them to **[-1, 1] range**
- Model receives completely different data than training â†’ predictions fail

**The Fix:**
```python
# CORRECT âœ… (New code)
# No normalization needed!
# MediaPipe outputs [0, 1], model expects [0, 1]
# Keep landmarks as-is
```

**Status**: âœ… **FIXED** in `ml_models/inference.py`

---

### 2. **TOO-HIGH CONFIDENCE THRESHOLDS**
**Location**: `ml_models/inference.py` and `translator/consumers.py`

**The Problem:**
```python
# OLD thresholds âŒ
if confidence > 0.65 and label_counts.get(predicted_label, 0) >= 2:
    # Only accept if confidence > 0.65 AND appeared 2+ times
```

**Why It's Wrong:**
- Your live data has different distribution than training data
- Real-time hand motion â‰  static training images
- Strict thresholds cause missed detections

**The Fix:**
```python
# NEW thresholds âœ…
if confidence > 0.5 and avg_confidence > 0.5:
    # Lowered from 0.65 to 0.5
    # Removed strict voting requirement (now 1 match, not 2)
```

**Status**: âœ… **FIXED** in both files

---

### 3. **STRICT VOTING LOGIC**
**Location**: `ml_models/inference.py` â†’ `predict()` method

**The Problem:**
```python
# OLD âŒ
if self.same_prediction_count >= 2:  # Requires 2 consecutive matches
    return prediction
```

**Why It's Wrong:**
- Requires frame to be seen twice before predicting
- ~100ms delay (2 frames @ 20 Hz)
- User sees slow response

**The Fix:**
```python
# NEW âœ…
if self.same_prediction_count >= 1:  # Return on first match
    return prediction
```

**Status**: âœ… **FIXED**

---

### 4. **TRAINING/INFERENCE MISMATCH**
**Location**: `ml_models/data_preprocessing.py` vs real-time landmarks

**The Problem:**
- Training data: Same-label sequences (10 frames of 'A', 10 frames of 'B')
- Real-time data: Continuous motion (transition between signs)
- Distribution mismatch

**Workaround**: Lower thresholds compensate (now done)

**Long-term Fix**: Retrain on real streaming sequences (future work)

---

## âœ… FIXES APPLIED

| Issue | File | Change | Status |
|---|---|---|---|
| Normalization | `inference.py` | Removed [-1, 1] conversion | âœ… Fixed |
| Confidence threshold | `inference.py` | 0.65 â†’ 0.5 | âœ… Fixed |
| Voting requirement | `inference.py` | 2 matches â†’ 1 match | âœ… Fixed |
| WebSocket threshold | `consumers.py` | 0.70 â†’ 0.50 | âœ… Fixed |

---

## ðŸ§ª HOW TO VERIFY FIXES WORK

### Option 1: Quick Test (Recommended)
```bash
python quick_test.py
```
- Opens webcam
- Makes predictions in real-time
- Shows if signs are being detected
- **Run this FIRST**

### Option 2: Diagnostic Tests
```bash
python test_detection.py
```
Runs 4 diagnostic tests:
1. MediaPipe hand detection capability
2. Landmark normalization check
3. Model input shape verification
4. Full pipeline test

### Option 3: Full System Test
Run the Django app:
```bash
python manage.py runserver
```
Then test via web UI

---

## ðŸ“Š EXPECTED IMPROVEMENTS

| Metric | Before | After |
|---|---|---|
| Detection threshold | 0.65 | 0.5 |
| Voting delay | ~100ms | ~50ms |
| Data distribution match | Poor (-1,1 range) | Perfect (0,1 range) |
| False positives | Fewer (high threshold) | More (lower threshold) |
| False negatives | Many (strict voting) | Fewer (lenient voting) |

---

## âš ï¸ IF IT STILL DOESN'T WORK

### Check 1: Is MediaPipe detecting hands?
```bash
python test_detection.py
# Look at TEST 1 output
```

**If NO hand detection:**
- âŒ Camera issue
- âŒ Lighting too dark
- âŒ Hand not visible to camera
- âœ… Solution: Better lighting, clear hand gesture

### Check 2: Is model loading?
```bash
python test_detection.py
# Look at TEST 3 output
```

**If model fails:**
- âŒ Missing `lstm_model.h5`
- âŒ Keras not installed
- âŒ Model corrupted
- âœ… Solution: Retrain model with `python ml_models/train_all.py`

### Check 3: Is full pipeline working?
```bash
python quick_test.py
```

**If predictions = 0:**
- Check camera and lighting (TEST 1)
- Check model (TEST 3)
- Look at console output for errors

---

## ðŸ”§ TECHNICAL DETAILS

### Landmark Flow (CORRECTED)

```
Camera (video frame)
    â†“
MediaPipe.hands.process()
    â†“
21 landmarks Ã— 3 coords Ã— 2 hands = 126 values
Range: [0, 1] for x/y, [0, 1] for z (depth)
    â†“ 
_normalize_landmarks() [NO CHANGE APPLIED]
    â†“
Still [0, 1] range âœ…
    â†“
sequence_buffer (collect 10 frames)
    â†“
LSTM model
    â†“
Output: Sign label + confidence
```

### Prediction Thresholds (NEW)

```python
# Receive prediction from model
if confidence > 0.5:              # â† Lowered from 0.65
    if avg_confidence > 0.5:      # â† New: average of 3 predictions
        if same_count >= 1:       # â† Changed from >= 2
            return prediction âœ…
```

---

## ðŸ“ CODE CHANGES SUMMARY

### `ml_models/inference.py`

**Change 1: Remove wrong normalization**
```python
# OLD:
landmarks = landmarks * 2.0 - 1.0

# NEW:
# No normalization - keep [0, 1] range
```

**Change 2: Lower thresholds**
```python
# OLD:
if confidence > 0.65 and label_counts.get(predicted_label, 0) >= 2:

# NEW:
if confidence > 0.5 and avg_confidence > 0.5:
```

**Change 3: Reduce voting requirement**
```python
# OLD:
if self.same_prediction_count >= 2:

# NEW:
if self.same_prediction_count >= 1:
```

### `translator/consumers.py`

**Change: Lower WebSocket threshold**
```python
# OLD:
if label is not None and confidence > 0.70:

# NEW:
if label is not None and confidence > 0.50:
```

---

## ðŸŽ¯ NEXT STEPS

1. **Run quick test**:
   ```bash
   python quick_test.py
   ```

2. **If works**: You're done! Signs should be detected now

3. **If not working**: Run diagnostic
   ```bash
   python test_detection.py
   # Check which test fails
   ```

4. **If model issue**: Retrain
   ```bash
   python ml_models/train_all.py
   ```

5. **If camera issue**: 
   - Better lighting (important!)
   - Closer to camera
   - Clearer hand gesture

---

## â“ FAQ

**Q: Why were these bugs not caught during training?**
A: Training uses pre-processed images (centered, controlled lighting). Real-time webcam data is different (variable lighting, motion blur, partial hands).

**Q: Will lower thresholds cause false positives?**
A: Yes, some. But better to detect signs and let user correct than miss valid signs.

**Q: Should I retrain the model?**
A: Not necessary - the fixes above should work. Only retrain if detection is still bad after fixes.

**Q: Can I adjust thresholds further?**
A: Yes! In `inference.py` line ~140:
```python
confidence > 0.5  # Can adjust to 0.4 (more lenient) or 0.6 (stricter)
```

---

## ðŸ“š REFERENCE

- **Normalized range issue**: Common in ML when training/inference data distributions differ
- **Threshold tuning**: Hyperparameter optimization - trade-off between precision and recall
- **Voting smoothing**: Temporal filtering to reduce jitter in video predictions

---

**Status**: âœ… All critical bugs identified and fixed
**Last Updated**: December 4, 2025
**Testing**: Use `quick_test.py` to verify
